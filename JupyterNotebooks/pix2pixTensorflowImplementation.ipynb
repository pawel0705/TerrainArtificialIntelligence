{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d013a074",
   "metadata": {
    "id": "d013a074"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0rlH-Km2-079",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rlH-Km2-079",
    "outputId": "3b265fa8-bc7d-47af-895f-93dbb41ca15d"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L # what gpu is used right now / (For Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NFlW0YK2-5F7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFlW0YK2-5F7",
    "outputId": "5864fce6-ac44-4fee-e400-2c2a278cdabb"
   },
   "outputs": [],
   "source": [
    "# mount google drive to notebook / (For Google Colab)\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea231622",
   "metadata": {
    "id": "ea231622"
   },
   "outputs": [],
   "source": [
    "# Parameters to change !!!\n",
    "\n",
    "EPOCHS = 401\n",
    "BUFFER_SIZE = 2500\n",
    "BATCH_SIZE = 25\n",
    "LAMBDA = 100\n",
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "# Picture paths. Division into several folders due to timeout returned by Google Colab with long disk access in one path.\n",
    "\n",
    "imagesTrainPath1 = '/content/gdrive/MyDrive/PythonCode/images/train512_11'\n",
    "imagesTrainPath2 = '/content/gdrive/MyDrive/PythonCode/images/train512_22'\n",
    "imagesTrainPath3 = '/content/gdrive/MyDrive/PythonCode/images/train512_33'\n",
    "imagesTrainPath4 = '/content/gdrive/MyDrive/PythonCode/images/train512_44'\n",
    "imagesTrainPath5 = '/content/gdrive/MyDrive/PythonCode/images/train512_55'\n",
    "imagesValPath = '/content/gdrive/MyDrive/PythonCode/images/val512'\n",
    "log_dir=\"/content/gdrive/MyDrive/PythonCode/train_logs/\"\n",
    "\n",
    "checkpoint_dir = '/content/gdrive/MyDrive/PythonCode/training_checkpoints'\n",
    "\n",
    "# Change generator and discriminator layers below if images are in different format than 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188be23c",
   "metadata": {
    "id": "188be23c"
   },
   "outputs": [],
   "source": [
    "def normalizeImage(inputImage, outputImage):\n",
    "    inputImage = (inputImage / 127.5) - 1\n",
    "    outputImage = (outputImage / 127.5) - 1\n",
    "\n",
    "    return inputImage, outputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22e766",
   "metadata": {
    "id": "ee22e766"
   },
   "outputs": [],
   "source": [
    "def loadImage(imageFile):\n",
    "    image = tf.io.read_file(imageFile)\n",
    "    image = tf.image.decode_png(image)\n",
    "\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    w = w // 2\n",
    "    outputImage = image[:, :w, :]\n",
    "    inputImage = image[:, w:, :]\n",
    "\n",
    "    inputImage = tf.cast(inputImage, tf.float32)\n",
    "    outputImage = tf.cast(outputImage, tf.float32)\n",
    "\n",
    "    return outputImage, inputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949ea77",
   "metadata": {
    "id": "f949ea77",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loadImageTrain(imageFile):\n",
    "    inputImage, outputImage = loadImage(imageFile)\n",
    "    inputImage, outputImage = normalizeImage(inputImage, outputImage)\n",
    "\n",
    "    return inputImage, outputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d64d26",
   "metadata": {
    "id": "e4d64d26"
   },
   "outputs": [],
   "source": [
    "def loadImageTest(imageFile):\n",
    "    inputImage, outputImage = loadImage(imageFile)\n",
    "    inputImage, outputImage = normalizeImage(inputImage, outputImage)\n",
    "\n",
    "    return inputImage, outputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f78a2d",
   "metadata": {
    "id": "22f78a2d"
   },
   "outputs": [],
   "source": [
    "def upsampleLayer(filters, size, shape, applyDropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2, batch_input_shape=shape,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if applyDropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def downsampleLayer(filters, size, shape, applyBatchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', batch_input_shape=shape, \n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if applyBatchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def createGenerator():\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=[512,512,3])\n",
    "\n",
    "    down_stack = [\n",
    "      downsampleLayer(32, 4, (None, 512, 512, 3), applyBatchnorm = False),\n",
    "      downsampleLayer(64, 4, (None, 256, 256, 32)),\n",
    "      downsampleLayer(128, 4, (None, 128, 128, 64)),\n",
    "      downsampleLayer(256, 4, (None, 64, 64, 128)),\n",
    "      downsampleLayer(512, 4, (None, 32, 32, 256)),\n",
    "      downsampleLayer(512, 4, (None, 16, 16, 512)),\n",
    "      downsampleLayer(512, 4, (None, 8, 8, 512)),\n",
    "      downsampleLayer(512, 4, (None, 4, 4, 512)),\n",
    "      downsampleLayer(512, 4, (None, 2, 2, 512)),\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "      upsampleLayer(512, 4, (None, 1, 1, 512), applyDropout=True),\n",
    "      upsampleLayer(512, 4, (None, 2, 2, 1024), applyDropout=True),\n",
    "      upsampleLayer(512, 4, (None, 4, 4, 1024), applyDropout=True),\n",
    "      upsampleLayer(512, 4, (None, 8, 8, 1024)),\n",
    "      upsampleLayer(256, 4, (None, 16, 16, 1024)),\n",
    "      upsampleLayer(128, 4, (None, 32, 32, 512)),\n",
    "      upsampleLayer(64, 4, (None, 64, 64, 256)),\n",
    "      upsampleLayer(128, 4, (None, 128, 128, 128)),\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                          strides=2,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=initializer,\n",
    "                                          activation='tanh')\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4a90d",
   "metadata": {
    "id": "7be4a90d"
   },
   "outputs": [],
   "source": [
    "def downsLayers(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', \n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def createDiscriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[512, 512, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[512, 512, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar])\n",
    "\n",
    "    down1 = downsLayers(64, 4, False)(x)\n",
    "    down2 = downsLayers(128, 4)(down1)\n",
    "    down3 = downsLayers(256, 4)(down2)\n",
    "    down4 = downsLayers(512, 4)(down3)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af24a5",
   "metadata": {
    "id": "f1af24a5"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c4cc5",
   "metadata": {
    "id": "eb6c4cc5"
   },
   "outputs": [],
   "source": [
    "discriminator = createDiscriminator()\n",
    "generator = createGenerator()\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877044b",
   "metadata": {
    "id": "1877044b"
   },
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af98662",
   "metadata": {
    "id": "9af98662"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar, epoch):\n",
    "    prediction = model(test_input, training=True)\n",
    "    \n",
    "    n_samples = 5\n",
    "    \n",
    "    if n_samples > BATCH_SIZE:\n",
    "        n_samples = BATCH_SIZE\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(test_input[i] * 0.5 + 0.5)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(prediction[i] * 0.5 + 0.5)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(tar[i] * 0.5 + 0.5)\n",
    "        \n",
    "    filename1 = '/content/gdrive/MyDrive/PythonCode/results/comparision_%06d.png' % (epoch+1)\n",
    "    plt.savefig(filename1, dpi=450)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf20fe1",
   "metadata": {
    "id": "ebf20fe1"
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224cc4e",
   "metadata": {
    "id": "4224cc4e"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('genTotalLoss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('genGanLoss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('genL1Loss', gen_l1_loss, step=epoch)\n",
    "        tf.summary.scalar('discLoss', disc_loss, step=epoch)\n",
    "        \n",
    "    return gen_total_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ccdd5",
   "metadata": {
    "id": "154ccdd5"
   },
   "outputs": [],
   "source": [
    "def train(train_ds, test_ds):\n",
    "    \n",
    "    bat_per_epo = int(number_files / BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        for example_input, example_target in test_ds.take(1):\n",
    "            generate_images(generator, example_input, example_target, epoch)\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print(str(int(n)) + \"/\" + str(bat_per_epo))\n",
    "            if (n+1) % 100 == 0:\n",
    "                print('')\n",
    "            gen_total_loss, disc_loss = train_step(input_image, target, epoch)\n",
    "            \n",
    "            g_total_loss = float(gen_total_loss)\n",
    "            d_loss = float(disc_loss)\n",
    "            print('Generator loss: {}; Discriminator loss: {}'.format(g_total_loss, d_loss))\n",
    "        print()\n",
    "\n",
    "        if (epoch) == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "            generator.save('/content/gdrive/MyDrive/PythonCode/results/generator_' + str(epoch) + '.h5')\n",
    "\n",
    "            \n",
    "\n",
    "        print ('Time for epoch {}: {} sec\\n'.format(epoch,\n",
    "                                                        time.time()-start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f68840",
   "metadata": {
    "id": "09f68840",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.list_files(imagesValPath + '/*.png')\n",
    "test_dataset = test_dataset.map(loadImageTest)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ACQfyXzRunxb",
   "metadata": {
    "id": "ACQfyXzRunxb"
   },
   "outputs": [],
   "source": [
    "train_dataset1 = tf.data.Dataset.list_files(imagesTrainPath1 + '/*.png')\n",
    "train_dataset2 = tf.data.Dataset.list_files(imagesTrainPath2 + '/*.png')\n",
    "train_dataset3 = tf.data.Dataset.list_files(imagesTrainPath3 + '/*.png')\n",
    "train_dataset4 = tf.data.Dataset.list_files(imagesTrainPath4 + '/*.png')\n",
    "train_dataset5 = tf.data.Dataset.list_files(imagesTrainPath5 + '/*.png')\n",
    "\n",
    "train_dataset = train_dataset1.concatenate(train_dataset2).concatenate(train_dataset3).concatenate(train_dataset4).concatenate(train_dataset5)\n",
    "\n",
    "train_dataset = train_dataset.map(loadImageTrain, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "number_files = len(list(os.listdir(imagesTrainPath1))) + len(list(os.listdir(imagesTrainPath2))) + len(list(os.listdir(imagesTrainPath3))) + len(list(os.listdir(imagesTrainPath4))) + len(list(os.listdir(imagesTrainPath5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48816e43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "48816e43",
    "outputId": "ed82beeb-1241-42d8-9753-599d90826a1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "train(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1f73f",
   "metadata": {
    "id": "86b1f73f"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "for example_input, example_target in test_dataset.take(5):\n",
    "    generate_images(generator, example_input, example_target, 99999)\n",
    "\n",
    "generator.save('/content/gdrive/MyDrive/PythonCode/results888/generator_finish.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "pix2pixTensorflowImplementation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
