{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab859bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bad4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downs(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', \n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def buildDiscriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downs(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downs(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downs(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720da406",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def downsample(filters, size, shape, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', batch_input_shape=shape, \n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, shape, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2, batch_input_shape=shape,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "def buildGenerator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "        downsample(64, 4, (None, 256, 256, 3), apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4, (None, 128, 128, 64)), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4, (None, 64, 64, 128)), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4, (None, 32, 32, 256)), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4, (None, 16, 16, 512)), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4, (None, 8, 8, 512)), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4, (None, 4, 4, 512)), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4, (None, 2, 2, 512)), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, (None, 1, 1, 512), apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "        upsample(512, 4, (None, 2, 2, 1024), apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, (None, 4, 4, 1024), apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4, (None, 8, 8, 1024)), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4, (None, 16, 16, 1024)), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4, (None, 32, 32, 512)), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4, (None, 64, 64, 256)), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                           strides=2,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=initializer,\n",
    "                                           activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf40a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables as per your need\n",
    "EPOCHS = 100\n",
    "BUFFER_SIZE = 14224\n",
    "BATCH_SIZE = 4\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f43f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
